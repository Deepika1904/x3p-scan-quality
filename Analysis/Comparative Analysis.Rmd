---
title: "Comparative Analysis: features of full and cropped scans"
author: "Craig Orman, Naga Vempati, Heike Hofmann"
date: "2022-12-09"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require(fastDummies)) install.packages('fastDummies')
if (!require(tidyverse)) install.packages('tidyverse')
if (!require(ggplot2)) install.packages('ggplot2')
if (!require(RColorBrewer)) install.packages('RColorBrewer')
if (!require(ggpubr)) install.packages('ggpubr')
if (!require(yardstick)) install.packages('yardstick')
if (!require(x3ptools)) install.packages('x3ptools')
library(fastDummies)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(ggpubr)
library(yardstick)
library(x3ptools)
theme_set(theme_bw())
## Load Functions - eventually we would like to just load a library

source("../R/comparison.R")
```

```{r data, echo=FALSE, cache=TRUE}
full_data = read.csv(file = "../data/std_and_cropped_data_12_20_2022.csv", header=TRUE)

# some prepping
full_data = full_data %>% mutate(
  Quality = factor(Quality, levels=c("Good", "Tiny Problems", "Problematic", "Bad", "Yikes")),
  Problem = factor(Problem),
  GoodScan = Quality %in% c("Good", "Tiny Problems") %>% factor(),
  LAPD_id = sprintf("FAU%3d-B%s-L%d",FAU, Bullet, Land)
)

followupScans <- data.frame()
```


# Comparison of features on Full and Cropped Scans

### TL;DR 

To conduct our analysis, we did a series of tests to compare the cropped version of a scan against the full version. We constructed scatter and box plots as well as ROC curves for visual analysis We trained a Generalized Linear Model (glm) to test the p scores, or importance, of each variable in the model, and constructed kernel density graphs to compare the scans. Every cropped scan and its full scan counterpart were found to have more than 90% correlation with each other, requiring us to use only one of them for each feature to avoid co-linearity issues.

[Extract NA](#extract-na), a measure of the total missing value count in the scan over the total value count. This feature performed better when it is cropped with no reservations. The ROC curve and p score in the glm were both better for the cropped image. The kernel density graph was also more distinct for the cropped image. 

[Assess Bottomempty](#assess-bottomempty), a measure of missing value count in the bottom 20% of the scan compared to the total value count in the same area. This feature performed better when it is cropped with no reservations. The ROC curve and p score in the glm were both better for the cropped image. The kernel density graph was also more distinct for the cropped image. 

[Assess Col NA](#assess-col-na), the proportion of columns in the scans matrix which have more than 20% missing values. This feature performed only marginally better when cropped. The ROC area difference is only 0.008, and the p scores for both features were found to be extremely significant. The kernal density graphs are very similar with the cropped graph being slightly more distinct.

[Assess Median NA Proportion](#assess-median-na-proportion), calculates the mean number of NA's in each column, and then finds the median out of all those values. This feature performed better when left as the full scan. The ROC area for the cropped was better by only 0.001, the p values for both features were found to be extremely significant, but the full scan was lower. The kernel density graph was more distinct for the full images. 

```{r, echo = FALSE}
feature_table <- data.frame(matrix(nrow = 4, ncol=5, dimnames=list(c("Extract NA", "Assess Bottomempty", "Assess Col NA", "Assess Median NA Proportion"), c("Correlation", "pvalue_Full", "pvalue_cropped", "auc_Full", "auc_Cropped"))))

feature_table[1,] <- c(0.908, "0.229", "<2e-16", 0.871, 0.902)
feature_table[2,] <- c(0.905, "5.86e-10", "<2e-16", 0.783, 0.859)
feature_table[3,] <- c(0.919, "1.62e-06", "1.17e-14", 0.888, 0.896)
feature_table[4,] <- c(0.908, "<2e-16", "6.77e-10", 0.907, 0.863)

knitr::kable(feature_table)
```

All of the features had significant outliers for their individual predictive power. We investigated the type I errors, false positives of a bad scan being predicted as good, and found them all to be "Tiny Problems" scans which could reasonably be re-classified as "problematic" or worse.

## Background and Introduction

This analysis is to compare the difference between the cropped versus non-cropped (full) version of a scan for quality identification. Cropped images have the potential for decreasing noise around the signal. The level of cropping we are considering is 5% from the left and right sides, and 10% off of the top of the image. In particular, we want to preserve the bottom of the image and the center as that is where most of the signal is. Below are examples of a full, full with marked edges, and a cropped image.

![Image of a scan without cropping](./Comparative-Analysis_files/figure-html/FAU-254-BB-L1.png)
![Image of a scan with the edges colored](./Comparative-Analysis_files/figure-html/FAU-254-BB-L1-masked.png)
![Image of a scan with cropping](./Comparative-Analysis_files/figure-html/FAU-254-BB-L1-Cropped.png)


## Features

xxx Overview of features with links (anchors)
We have identified four potential features of our scan quality assessor which could benefit from being cropped. 
XXX move mathematical definitions that you need for multiple features here. Give the definitions numbers or names and then refer to these definitions as needed below.

[Extract NA](#extract-na)

The function `extract_na` calculates the percentage of missing values in the scan (part) under observation, e.g. for scan surface matrix $X \in {\rm I\!R}^{m, n}$ the percentage of missing values is defined as:

Let $A=\{NA\}$ be the set of undefined values. For simplicity of notation we will assume that the space of real values ${\rm I\!R}$ contains $A$:
${\rm I\!R}:= {\rm I\!R} \cup A$. 

With that, let $X \in {\rm I\!R}^{m,n}$ be a real-valued surface matrix of dimensions m x n where m and n are strictly positive integer values, $X = (x_{ij})_{1 \leq i \leq m, 1 \leq j \leq n}$ The proportion of missing values in X is then defined as: 
$$
\frac{1}{m*n} \sum^m_{i=1} \sum^n_{j=1} \theta_A(x_{ij}) \\
\text{Where } \theta_A(x) = \left\{\begin{aligned}
&1 &&: \text{if }x \in A\\
&0 &&: \text{otherwise}\\
\end{aligned} \right.
$$
[Assess Bottomempty](#assess-bottomempty)

The feature `assess_bottomempty` calculates the percentage of missing values in the bottom 20% of the scan. 

Let $A=\{NA\}$ be the set of undefined values. For simplicity of notation we will assume that the space of real values ${\rm I\!R}$ contains $A$:
${\rm I\!R}:= {\rm I\!R} \cup A$. 

With that, let $X \in R^{m,n}$ be a real-valued surface matrix of dimensions m x n where m and n are strictly positive integers $X = (x_{ij})_{1 \leq i \leq m, 1 \leq j \leq n}$.

Let $R \subseteq {\rm I\!R}$ be a set of size m, where each element is the sum of the NA's for the given row, defined as:
$$
\forall i \in R: R_i = \sum^n_{j=1} \theta_A(x_{ij}) \\
\text{Where } \theta_A(x) = \left\{\begin{aligned}
&1 &&: \text{if }x \in A\\
&0 &&: \text{otherwise}\\
\end{aligned} \right.
$$

Let $B \subset R$ be a set, which is the set of all values in $R_i$, given that $i \geq m*0.8$. Therefore, the proportion of missing values in $X$'s bottom 20% can be given by:
$$
\frac{1}{m*n*0.2}\sum_{i=1}^{m*0.2}(R_i)*100
$$
[Assess Col NA](#assess-col-na)

The function `assess_col_na` calculates the percentage of missing values 

For every column in the matrix of a scan, we find the proportion of scans in that column which are NA. Then we count how many of the columns whose proportion is greater than 20%, the pre-determined threshold of acceptable NA's. Then we divide by the number of columns * 0.2 to get our final threshold adjusted number. 

Let $A=\{NA\}$ be the set of undefined values. For simplicity of notation we will assume that the space of real values ${\rm I\!R}$ contains $A$:
${\rm I\!R}:= {\rm I\!R} \cup A$. 

With that, let $X \in R^{m,n}$ be a real-valued surface matrix of dimensions m x n where m and n are strictly positive integers $X = (x_{ij})_{1 \leq i \leq m, 1 \leq j \leq n}$.

Let $R \subseteq {\rm I\!R}$ be a set of size n, where each element is the sum of the NA's for the given column, defined as:
$$
\forall i \in R: R_i = \sum^m_{j=1} \theta_A(x_{ij}) \\
\text{Where } \theta_A(x) = \left\{\begin{aligned}
&1 &&: \text{if }x \in A\\
&0 &&: \text{otherwise}\\
\end{aligned} \right.
$$

We define $P$ as the proportion of all NAs per column for every row, as defined here:
$$
\forall i \in R: P_i = \frac{R_i}{n} * 100
$$

We now find the proportion of threshold adjusted columns in the matrix 
$$
\frac{\sum_{i=1}^n(P_i*\beta_B(P_i))}{n*0.2} \\
\text{Where } \beta_B(x) = \left\{\begin{aligned}
&1 &&: \text{if }x > 20\\
&0 &&: \text{otherwise}\\
\end{aligned} \right.
$$

[Assess Median NA proportion](#assess-median-na-proportion)

The function `assess_median_na_proportion` calculates the mean number of NA's in each column, and then finds the median out of all those values.

Let $A=\{NA\}$ be the set of undefined values. For simplicity of notation we will assume that the space of real values ${\rm I\!R}$ contains $A$:
${\rm I\!R}:= {\rm I\!R} \cup A$. 

With that, let $X \in R^{m,n}$ be a real-valued surface matrix of dimensions m x n where m and n are strictly positive integers $X = (x_{ij})_{1 \leq i \leq m, 1 \leq j \leq n}$.

Let $R \subseteq {\rm I\!R}$ be a set of size n, where each element is the mean of the NA's for the given column, defined as:
$$
\forall i \in R: R_i = \frac{\sum^m_{j=1} \theta_A(x_{ij})}{m} \\
\text{Where } \theta_A(x) = \left\{\begin{aligned}
&1 &&: \text{if }x \in A\\
&0 &&: \text{otherwise}\\
\end{aligned} \right.
$$

We then sort, and select the median of $R$

## Appendix

### Extract NA

#### Which of the features is better for discriminating between good and bad scans?

```{r echo=FALSE}
correlation <- cor(full_data$extract_na, full_data$extract_na_cropped)

res <- comparison(data.frame(full_data$extract_na, full_data$extract_na_cropped, full_data$Quality), feature = "Extract NA")

res$scatterplot + coord_equal()

res$boxplot

res$roc_curve

print(paste("Extract NA. Correlation: ", round(correlation, 3), "Full AUC:", round(res$roc_auc$Full_AUC, 3), "Cropped AUC: ", round(res$roc_auc$Cropped_AUC, 3)))

knitr::kable(res$summ, caption=attr(res$summ, "title"))

```
#### Should we use features from just one type of scan or both?

```{r, echo=FALSE}
# logistic regression in the two features
logistic_base <- glm(GoodScan~extract_na+extract_na_cropped, data = full_data, family = binomial())
summary(logistic_base)

# extract_na_cropped is the better single predictor. 
full_data %>% pivot_longer(starts_with("extract_na"), names_to="Scan") %>% 
  ggplot(aes(x = value, fill=GoodScan, color=GoodScan)) +
  geom_density(alpha=0.8) +
  scale_fill_manual(values=col_scans_light) +
  scale_colour_manual(values=col_scans_dark) +
  facet_grid(.~Scan)

```


#### Conclusion for Extract NA

The values for feature `extract_NA` are highly correlated between the cropped and the full scan. 

Using good and scans with only tiny problems as overall 'good' scans, the feature applied to cropped scans has an increased accuracy compared to the feature values from the full scan. 

We might want to follow up on the orange colored scans:

```{r echo=FALSE, fig.height=3}
full_data  <- full_data %>% 
  mutate(followup=GoodScan=="TRUE" & extract_na_cropped>15)
full_data %>% 
  ggplot(aes(x = extract_na_cropped, y = GoodScan, color = followup)) + 
  geom_jitter() +
  scale_colour_manual(values=c("grey50", "darkorange"))


```
```{r}

full_data$LAPD_id[full_data$followup]

followupScans <- rbind(followupScans, full_data[full_data$followup == TRUE,])
# All followups for extract_na are mislabelled scans. They are all labelled as tiny problems but should be problematic or worse.
```

```{r, include = FALSE, eval = FALSE}
library(x3ptools)
# /media/Raven/LAPD
f1 <- x3p_read("/media/Raven/LAPD/FAU 263/Bullet A/LAPD - 263 - Bullet A - Land 4 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
# FAU263-BA-L4 is labelled tiny-problems but should be labelled Problematic or worse

f2 <- x3p_read("/media/Raven/LAPD/FAU 263/Bullet C/LAPD - 263 - Bullet C - Land 1 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
# FAU263-BC-L1 is labelled tiny-problems but should be labelled Problematic or worse

f3 <- x3p_read("/media/Raven/LAPD/FAU 263/Bullet C/LAPD - 263 - Bullet C - Land 3 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
# FAU263-BC-L3 is labelled tiny-problems but should be labelled Problematic or worse

f4 <- x3p_read("/media/Raven/LAPD/FAU 287/Bullet C/LAPD - 287 - Bullet C - Land 5 - Sneox1 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
# FAU287-BC-L5 is labelled tiny-problems but should be labelled Problematic or worse

f5 <- x3p_read("/media/Raven/LAPD/FAU 154/Bullet D/LAPD - 154 - Bullet D - Land 2 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Carley McConnell.x3p")
# FAU154-BD-L2 is labelled tiny-problems but should be labelled Problematic or worse

f6 <- x3p_read("/media/Raven/LAPD/FAU 277/Bullet A/LAPD - 277 - Bullet A - Land 4 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
# FAU277-BA-L4 is labelled tiny-problems but should be labelled Problematic or worse

f7 <- x3p_read("/media/Raven/LAPD/FAU 286/Bullet A/LAPD - 286 - Bullet A - Land 5 - Sneox1 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
# FAU286-BA-L5 is labelled tiny-problems but should be labelled Problematic or worse
```


### Assess Bottomempty

#### Which of the features is better for discriminating between good and bad scans?

```{r echo=FALSE}
correlation <- cor(full_data$assess_bottomempty, full_data$assess_bottomempty_cropped)

res <- comparison(data.frame(full_data$assess_bottomempty, full_data$assess_bottomempty_cropped, full_data$Quality), feature = "Assess Bottomempty")
res$scatterplot + coord_equal()

res$boxplot

res$roc_curve

print(paste("Assess Bottomempty. Correlation: ", round(correlation, 3), "Full AUC:", round(res$roc_auc$Full_AUC, 3), "Cropped AUC: ", round(res$roc_auc$Cropped_AUC, 3)))

knitr::kable(res$summ, caption=attr(res$summ, "title"))

```
#### Should we use features from just one type of scan or both?

```{r, echo=FALSE}
# logistic regression in the two features
logistic_base <- glm(GoodScan~assess_bottomempty+assess_bottomempty_cropped, data = full_data, family = binomial())
summary(logistic_base)

# assess_bottomempty_cropped is the better single predictor. 
full_data %>% pivot_longer(starts_with("assess_bottomempty"), names_to="Scan") %>% 
  ggplot(aes(x = value, fill=GoodScan, color=GoodScan)) + geom_density(alpha=0.8) + scale_fill_manual(values=col_scans_light) + scale_colour_manual(values=col_scans_dark) +
  facet_grid(.~Scan)
```


#### Conclusion for Assess Bottomempty

The values for feature `assess_bottomempty` are highly correlated between the cropped and the full scan. 

Using good and scans with only tiny problems as overall 'good' scans, the feature applied to cropped scans has an increased accuracy compared to the feature values from the full scan. 

We might want to follow up on the orange colored scans:

```{r echo=FALSE, fig.height=3}
full_data  <- full_data %>% 
  mutate(followup=GoodScan=="TRUE" & assess_bottomempty_cropped>30)
full_data %>% 
  ggplot(aes(x = assess_bottomempty_cropped, y = GoodScan, color = followup)) + 
  geom_jitter() +
  scale_colour_manual(values=c("grey50", "darkorange"))
```
```{r}
full_data$LAPD_id[full_data$followup]

followupScans <- rbind(followupScans, full_data[full_data$followup == TRUE,])
```

```{r, include = FALSE, eval = FALSE}
# All problems are registered as tiny problems
followup <- c("FAU263-BA-L4", "FAU287-BC-L5", "FAU254-BD-L4", "FAU275-BC-L5", "FAU275-BD-L3", "FAU277-BA-L4", "FAU286-BA-L5")
f1 <- x3p_read("/media/Raven/LAPD/FAU 263/Bullet A/LAPD - 263 - Bullet A - Land 4 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
image(f1, main=followup[1])

f2 <- x3p_read("/media/Raven/LAPD/FAU 287/Bullet C/LAPD - 287 - Bullet C - Land 5 - Sneox1 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
image(f2, main=followup[2])

f3 <- x3p_read("/media/Raven/LAPD/FAU 254/Bullet D/LAPD - 254 - Bullet D - Land 4 - Sneox2 - 20x - auto light left image +20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
image(f3, main=followup[3])

f4 <- x3p_read("/media/Raven/LAPD/FAU 275/Bullet C/LAPD - 275 - Bullet C - Land 5 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
image(f4, main=followup[4])

f5 <- x3p_read("/media/Raven/LAPD/FAU 275/Bullet D/LAPD - 275 - Bullet D - Land 3 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
image(f5, main=followup[5])

f6 <- x3p_read("/media/Raven/LAPD/FAU 277/Bullet A/LAPD - 277 - Bullet A - Land 4 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
image(f6, main=followup[6])

f7 <- x3p_read("/media/Raven/LAPD/FAU 286/Bullet A/LAPD - 286 - Bullet A - Land 5 - Sneox1 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
image(f7, main=followup[7])

```


### Assess Col NA

#### Which of the features is better for discriminating between good and bad scans?

```{r echo=FALSE}
correlation <- cor(full_data$assess_col_na, full_data$assess_col_na_cropped)

res <- comparison(data.frame(full_data$assess_col_na, full_data$assess_col_na_cropped, full_data$Quality), feature = "Assess Col NA")

res$scatterplot + coord_equal()

res$boxplot

res$roc_curve

print(paste("Assess Col NA Correlation: ", round(correlation, 3), "Full AUC:", round(res$roc_auc$Full_AUC, 3), "Cropped AUC: ", round(res$roc_auc$Cropped_AUC, 3)))

knitr::kable(res$summ, caption=attr(res$summ, "title"))

```
#### Should we use features from just one type of scan or both?

```{r, echo=FALSE}
# logistic regression in the two features
logistic_base <- glm(GoodScan~assess_col_na+assess_col_na_cropped, data = full_data, family = binomial())
summary(logistic_base)

# Both predictors are about the same.
full_data %>% pivot_longer(starts_with("assess_col_na"), names_to="Scan") %>% 
  ggplot(aes(x = value, fill=GoodScan, color=GoodScan)) + geom_density(alpha=0.8) + scale_fill_manual(values=col_scans_light) + scale_colour_manual(values=col_scans_dark) +
  facet_grid(.~Scan)
```


#### Conclusion for Assess Col NA

The values for feature `assess_col_na` are highly correlated between the cropped and the full scan. 

Using good and scans with only tiny problems as overall 'good' scans, the feature applied to cropped scans has an increased accuracy compared to the feature values from the full scan. 

We might want to follow up on the orange colored scans:

```{r echo=FALSE, fig.height=3}
full_data  <- full_data %>% 
  mutate(followup=GoodScan=="TRUE" & assess_col_na_cropped>1.35)
full_data %>% 
  ggplot(aes(x = assess_col_na_cropped, y = GoodScan, color = followup)) + 
  geom_jitter() +
  scale_colour_manual(values=c("grey50", "darkorange"))
```
```{r}
full_data$LAPD_id[full_data$followup]

followupScans <- rbind(followupScans, full_data[full_data$followup == TRUE,])
```

```{r, include = FALSE, eval = FALSE}
followup <- data.frame(LAPD_ID = c("FAU263-BA-L4", "FAU263-BB-L3", "FAU263-BC-L1", "FAU263-BC-L3", "FAU154-BD-L2", "FAU286-BA-L5"), filePAth = c("/media/Raven/LAPD/FAU 263/Bullet A/LAPD - 263 - Bullet A - Land 4 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p", "/media/Raven/LAPD/FAU 263/Bullet B/LAPD - 263 - Bullet B - Land 3 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p", "/media/Raven/LAPD/FAU 263/Bullet C/LAPD - 263 - Bullet C - Land 1 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p", "/media/Raven/LAPD/FAU 263/Bullet C/LAPD - 263 - Bullet C - Land 3 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p", "/media/Raven/LAPD/FAU 154/Bullet D/LAPD - 154 - Bullet D - Land 2 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Carley McConnell.x3p"  , "/media/Raven/LAPD/FAU 286/Bullet A/LAPD - 286 - Bullet A - Land 5 - Sneox1 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p"))

for (i in 1:nrow(followup)) {
  f <- x3p_read(followup[i,2])
  image(f, main=followup[i,1])
}
```

### Assess Median NA Proportion

#### Which of the features is better for discriminating between good and bad scans?

```{r echo=FALSE}
correlation <- cor(full_data$extract_na, full_data$extract_na_cropped)


res <- comparison(data.frame(full_data$assess_median_na_proportion, full_data$assess_median_na_proportion_cropped, full_data$Quality), feature = "Assess median NA proportion")

res$scatterplot + coord_equal()

res$boxplot

res$roc_curve

print(paste("Assess Median NA Proportion. Correlation: ", round(correlation, 3), "Full AUC:", round(res$roc_auc$Full_AUC, 3), "Cropped AUC: ", round(res$roc_auc$Cropped_AUC, 3)))

knitr::kable(res$summ, caption=attr(res$summ, "title"))

```
#### Should we use features from just one type of scan or both?

```{r, echo=FALSE}
# logistic regression in the two features
logistic_base <- glm(GoodScan~assess_median_na_proportion+assess_median_na_proportion_cropped,
                     data = full_data, family = binomial())
summary(logistic_base)

# assess_median_na_proportion is the better single predictor. 
full_data %>% pivot_longer(starts_with("assess_median_na_proportion"), names_to="Scan") %>% 
  ggplot(aes(x = value, fill=GoodScan, color=GoodScan)) + geom_density(alpha=0.8) + scale_fill_manual(values=col_scans_light) + scale_colour_manual(values=col_scans_dark) +
  facet_grid(.~Scan)
```


#### Conclusion for Assess Median NA Proportion

The values for feature `extract_NA` are highly correlated between the cropped and the full scan. 

Using good and scans with only tiny problems as overall 'good' scans, the feature applied to full scans has an increased accuracy compared to the feature values from the cropped scan. 

We might want to follow up on the orange colored scans:

```{r echo=FALSE, fig.height=3}
full_data  <- full_data %>% 
  mutate(followup=GoodScan=="TRUE" & assess_median_na_proportion>0.095)
full_data %>% 
  ggplot(aes(x = assess_median_na_proportion, y = GoodScan, color = followup)) + 
  geom_jitter() +
  scale_colour_manual(values=c("grey50", "darkorange"))
```
```{r}
full_data$LAPD_id[full_data$followup]

followupScans <- rbind(followupScans, full_data[full_data$followup == TRUE,])
```
```{r, include = FALSE, eval = FALSE}
followup <- data.frame(LAPD_ID = c("FAU263-BC-L3", "FAU154-BD-L2", "FAU204-BC-L4"), filePAth = c("/media/Raven/LAPD/FAU 263/Bullet C/LAPD - 263 - Bullet C - Land 3 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p", "/media/Raven/LAPD/FAU 154/Bullet D/LAPD - 154 - Bullet D - Land 2 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Carley McConnell.x3p", "/media/Raven/LAPD/FAU 204/Bullet C/LAPD - 204 - Bullet C - Land 4 - Sneox1 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p"))

for (i in 1:nrow(followup)) {
  f <- x3p_read(followup[i,2])
  image(f, main=followup[i,1])
}
# all should be relabbeled, FAU 204, BC, L4 is particularly Yikes looking
```

### Followup Scans

```{r}
followupUnique <- followupScans[duplicated(followupScans) == FALSE,]
followupScans %>% group_by(followupScans$LAPD_id) %>% summarize(
  count = n()
)

# 3 hits: FAU154-BD-L2, FAU263-BA-L4, FAU263-BC-L3, FAU286-BA-L5
# 2 hits: FAU263-BC-L1, FAU277-BA-L4, FAU287-BC-L5
# 1 hits: FAU204-BC-L4, FAU254-BD-L4, FAU263-BB-L3, FAU275-BC-L5, FAU275-BD-L3
```

```{r, eval=FALSE}
FAU263_BA_L4 <- x3p_read("../data/followup_scans/LAPD - 263 - Bullet A - Land 4 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
FAU263_BC_L1 <- x3p_read("../data/followup_scans/LAPD - 263 - Bullet C - Land 1 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
FAU263_BC_L3 <- x3p_read("../data/followup_scans/LAPD - 263 - Bullet C - Land 3 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
FAU277_BA_L4 <- x3p_read("../data/followup_scans/LAPD - 277 - Bullet A - Land 4 - Sneox2 - 20x - auto light left image + 20% - threshold 2 - resolution 4 - Connor Hergenreter.x3p")
x3p_image(FAU263_BA_L4, file="./Comparative-Analysis_files/figure-html/FAU263_BA_L4.png")
x3p_image(FAU263_BC_L1, file="./Comparative-Analysis_files/figure-html/FAU263-BC-L1.png")
x3p_image(FAU263_BC_L3, file="./Comparative-Analysis_files/figure-html/FAU263_BC_L3.png")
x3p_image(FAU277_BA_L4, file="./Comparative-Analysis_files/figure-html/FAU277-BA-L4.png")
```
# 3 hits: FAU154-BD-L2, FAU263-BA-L4, FAU263-BC-L3, FAU286-BA-L5
# 2 hits: FAU263-BC-L1, FAU277-BA-L4, FAU287-BC-L5
# 1 hits: FAU204-BC-L4, FAU254-BD-L4, FAU263-BB-L3, FAU275-BC-L5, FAU275-BD-L3
```{r, echo = FALSE}
followup_table <- data.frame(matrix(nrow = 12, ncol=5, dimnames=list(c(), c("LAPD-ID", "Hit-Count", "Current-Quality", "Current-Problem", "Recommended-Quality"))))
followup_table[,1] = followupCleaned$LAPD_id
followup_table[,2] = c(3, 2, 3, 2, 3, 2, 3, 1, 1, 1, 1, 1)
followup_table[,3] = followupCleaned$Quality
followup_table[,4] = followupCleaned$Problem
followup_table <- followup_table[order(-followup_table$Hit.Count),]
knitr::kable(followup_table)
```

![FAU263_BA_L4 Image](./Comparative-Analysis_files/figure-html/FAU263_BA_L4.png)
FAU263_BA_L4 (Tiny Problems, Feathering): Significant feathering on right side image, missing most of the left, and many missing values on bottom 

![FAU263_BC_L1 Image](./Comparative-Analysis_files/figure-html/FAU263-BC-L1.png)
FAU263_BC_L1 (Tiny Problems, Feathering): Significant feathering on right hand side, left side is missing most of the values, then feathering, then holes as it moves towards the middle. Bottom is also speckled with missing values.

![FAU263_BC_L3 Image](./Comparative-Analysis_files/figure-html/FAU263_BC_L3.png)
FAU263_BC_L3 (Tiny Problems, Feathering): Contains significant feathering, holes, disproportionate edges and missing values at the bottom. 

![FAU277_BA_L4 Image](./Comparative-Analysis_files/figure-html/FAU277-BA-L4.png)
FAU263_BC_L1 (Tiny Problems, Holes): A few holes, significant missing values on the left, right, and bottom.
